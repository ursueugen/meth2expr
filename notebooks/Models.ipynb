{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f01dac7cfb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(RNNRegressor, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.i2h = nn.Linear(input_dim + hidden_dim, hidden_dim)\n",
    "        self.i2o = nn.Linear(input_dim + hidden_dim, output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        #input = input.view(-1, input.shape[1])\n",
    "        # TODO: Modify code to accept batch tensors <loc, batch_nr, index>. Can add init hidden in here.\n",
    "        \n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.tanh(output)\n",
    "\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_dim)\n",
    "\n",
    "HIDDEN_DIM = 10\n",
    "rnn = RNNRegressor(train_set.vocab_size, HIDDEN_DIM, 1)\n",
    "\n",
    "\n",
    "\n",
    "writer = SummaryWriter('runs/RNN_playground')\n",
    "writer.add_graph(rnn, (seq2tensor(\"ACGTT\")[1], torch.zeros(1, HIDDEN_DIM)))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "def train(output_tensor, seq_tensor):\n",
    "    ''''''\n",
    "    \n",
    "    hidden = rnn.initHidden()\n",
    "    \n",
    "    # zero the grad buffers\n",
    "    rnn.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward pass\n",
    "    for i in range(seq_tensor.shape[0]):\n",
    "        output, hidden = rnn(seq_tensor[i], hidden)\n",
    "    \n",
    "    # compute loss and backward pass\n",
    "    loss = criterion(output, output_tensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    # update params\n",
    "    optimizer.step()\n",
    "    \n",
    "    return output, loss.item()\n",
    "\n",
    "train(torch.tensor([-0.0117]), seq2tensor(\"ACGTN\"))\n",
    "print(seq2tensor(\"ACGTN\").shape, torch.tensor([-0.0118]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "# TODO: not really minibatch for now\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        # get inputs\n",
    "        # TODO: Account for dtypes, otherwise get incompatible!\n",
    "        seq_tensor, expr = data\n",
    "        seq_tensor = seq_tensor[0]\n",
    "        expr = expr[0].view(1)\n",
    "        expr = expr.type(torch.FloatTensor)  \n",
    "        \n",
    "        # train on example\n",
    "        output, loss = train(expr[0], seq_tensor)\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# save model\n",
    "PATH = './models/test_model'\n",
    "torch.save(rnn.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict loop\n",
    "\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for data in testloader:\n",
    "#         images, labels = data\n",
    "#         outputs = net(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "#     100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
